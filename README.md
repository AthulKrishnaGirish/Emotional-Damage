<img width="3188" height="1202" alt="frame (3)" src="https://github.com/user-attachments/assets/517ad8e9-ad22-457d-9538-a9e62d137cd7" />


# "Emotional Damage"


## Basic Details
### Team Name:(Individual Participation)


### Team Members
- Team Lead: Athul Krishna Girish - Model Engineering College, Thrikkakkara, Kochi, Kerala

### Project Description
Emotional Damage is a desktop GUI built with Python and OpenCV that playfully assigns emotions to inanimate objects through computer vision. Using a live webcam feed, the app detects an object's dominant color and reveals its "secret feelings" through a humorous, pre-written emotional profile that is, it assigns a whimsical "emotion" from a curated list of funny profiles. It's a fun take on AI, imagining the secret emotional lives of everyday things.

### The Problem (that doesn't exist)
Why dont we care about the things we use everyday? They too will be having emotions and feelings to share. Just try to undertstand them......

### The Solution (that nobody asked for)
And here comes me standing strong for the inanimate objects to express their feelings to the world through my GUI where each object is given their rights to express their feelings.

## Technical Details
### Technologies/Components Used
#For Software:-
Languages used:
- Python: The core programming language used to write the entire application logic.
  
Frameworks used:
- PyQt6: The GUI framework used to build the entire desktop application window, including all the labels, buttons, and layouts. It's a Python binding   for the powerful Qt C++ framework.
- OpenCV (cv2): The primary computer vision library used for capturing the webcam feed, converting color spaces (from BGR to HSV), and processing     images to detect colors.
  
Libraries Used:
 - NumPy: A fundamental library for scientific computing, used here specifically to create the arrays that define the HSV color ranges for detection.
 - Python Standard Libraries: Also used several built-in libraries, including sys (for system-specific parameters), random (to choose loading taglines     and random emotions), and time (to pause the video thread).

   
Tools used:
  - pip: The package installer for Python, used to install the external libraries (PyQt6, opencv-python, numpy).
  - Code Editor / IDE: The software used to write and edit the app.py file (e.g., VS Code, PyCharm, etc.).
  - Git / GitHub: The version control system and platform used to manage your project repository and create the README.md file


### Implementation
For Software:
# Installation
.  **Clone the repository:**
    ```bash
    git clone [https://github.com/AthulKrishnaaGirish/Emotional-Damage.git](https://github.com/AthulKrishnaaGirish/Emotional-Damage.git)
    ```

2.  **Navigate to the project directory:**
    ```bash
    cd Emotional-Damage
    ```

3.  **Create and activate a virtual environment (Recommended):**
    * On Windows:
        ```bash
        python -m venv venv
        .\venv\Scripts\activate
        ```
    * On macOS/Linux:
        ```bash
        python3 -m venv venv
        source venv/bin/activate
        ```

4.  **Install the required packages:**
    ```bash
    pip install -r requirements.txt
    ```

# Run
```bash
   python app.py
```
# Project Documentation
For Software:

# Screenshots 
<img width="1920" height="1080" alt="CodeLines" src="https://github.com/user-attachments/assets/a86f08da-1920-43e8-a7c9-c5ccf9313a0e" />

*First few Code lines of the project*

<img width="1920" height="1080" alt="GUI interface" src="https://github.com/user-attachments/assets/547ec7d7-65de-4862-86a8-52778726c1ab" />

*The image shows the window of the project/GUI interface that appears on running the python code*

<img width="1920" height="1080" alt="predictionoutput" src="https://github.com/user-attachments/assets/968d777e-a411-42e6-b3eb-b2f22f0aa2b3" />

*Interface with the predicted output connecting the colour of the object and its emotion.*



### Project Demo
# Video
link : https://drive.google.com/file/d/1669aECt-q0Hzfnkm-n7BSzP86WS9Fuk6/view?usp=drive_link
*The video demonstrates how the object is detected through the web cam and classiffied by the code according to its colour and a related emotion is assigned.
Like, Apple--->Red---->Fiery Passion
      plants--->Green-->Zen Master*



## Team Contributions
Individual Participation-Full Contribution

---
Made with ❤️ at TinkerHub Useless Projects 

![Static Badge](https://img.shields.io/badge/TinkerHub-24?color=%23000000&link=https%3A%2F%2Fwww.tinkerhub.org%2F)
![Static Badge](https://img.shields.io/badge/UselessProjects--25-25?link=https%3A%2F%2Fwww.tinkerhub.org%2Fevents%2FQ2Q1TQKX6Q%2FUseless%2520Projects)


